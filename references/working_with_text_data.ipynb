{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WorkingWithText",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD9EMmCA1prr",
        "colab_type": "text"
      },
      "source": [
        "# **Working with text**\n",
        "\n",
        "\n",
        ">\n",
        "\n",
        "**Step 1. Import your data**\n",
        "\n",
        "**Step 2. Clean text**\n",
        "* Encoding errors\n",
        "* HTML tags\n",
        "* Punctuations (regular expression)\n",
        "\n",
        "**Step 3. Tokenization**\n",
        "* Word_tokenizer\n",
        "* Regex_tokenizer\n",
        "\n",
        "**Step 4. More processing**\n",
        "* Removing stop words\n",
        "* Lemmatization\n",
        "* Stemming\n",
        "\n",
        "**Step 5. Text featurization**\n",
        "- Bag of Words\n",
        "- N-gram\n",
        "- Word Embedding\n",
        "...\n",
        "\n",
        ".\n",
        "\n",
        "**TorchText**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slpTjSGTFaeN",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-5VClbF1Yyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGJk3bYUFWVS",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f_dCWzIlb-o",
        "colab_type": "text"
      },
      "source": [
        "## **Step 1. Import your data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20o79Q_R3evP",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSYh1xRd6CEA",
        "colab_type": "text"
      },
      "source": [
        "**What's in *example.txt*:**\n",
        "\n",
        "< p >\n",
        "\n",
        "\"Christmas won't be Christmas without any presents,\" grumbled Jo, lying on the rug.< br >\n",
        "\"It's so dreadful to be poor!\" sighed Meg, looking down at her old dress.< br >\n",
        "\"I don't think it's fair for some girls to have plenty of pretty things, and other girls nothing at all,\" added little Amy, with an injured sniff.< br >\n",
        "\"We've got Father and Mother, and each other,\" said Beth contentedly from her corner.< br >\n",
        "The four young faces on which the firelight shone brightened at the cheerful words, but darkened again as Jo said sadly, \"We haven't got Father, and shall not have him for a long time.\" She didn't say \"perhaps never,\" but each silently added it, thinking of Father far away, where the fighting was.< br >\n",
        "\n",
        "< /p >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si7cSLWA6CA0",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnbttwclZ4Vj",
        "colab_type": "code",
        "outputId": "cb1a7e81-ae84-478f-9a39-2dce79fd5987",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# google file open\n",
        "file_path = \"./example.txt\"\n",
        "if not os.path.isfile(file_path):\n",
        "    uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a809e6e0-1fe9-4cc1-afb9-9e6cae3bea5c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a809e6e0-1fe9-4cc1-afb9-9e6cae3bea5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving example.txt to example.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tVeIbmvcdhr",
        "colab_type": "code",
        "outputId": "c67c89b1-51c3-4964-9cf2-70d2c26591b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "# OS file open\n",
        "with open(file_path, \"r\") as f:\n",
        "    data = [line for line in f.readlines()]\n",
        "\n",
        "pprint.pprint(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<p>\\n',\n",
            " '\"Christmas won\\'t be Christmas without any presents,\" grumbled Jo, lying on '\n",
            " 'the rug.<br>\\n',\n",
            " '\"It\\'s so dreadful to be poor!\" sighed Meg, looking down at her old '\n",
            " 'dress.<br>\\n',\n",
            " '\"I don\\'t think it\\'s fair for some girls to have plenty of pretty things, '\n",
            " 'and other girls nothing at all,\" added little Amy, with an injured '\n",
            " 'sniff.<br>\\n',\n",
            " '\"We\\'ve got Father and Mother, and each other,\" said Beth contentedly from '\n",
            " 'her corner.<br>\\n',\n",
            " 'The four young faces on which the firelight shone brightened at the cheerful '\n",
            " 'words, but darkened again as Jo said sadly, \"We haven\\'t got Father, and '\n",
            " 'shall not have him for a long time.\" She didn\\'t say \"perhaps never,\" but '\n",
            " 'each silently added it, thinking of Father far away, where the fighting '\n",
            " 'was.<br>\\n',\n",
            " '</p>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hb1BfuNFx24",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpavuwAla5zJ",
        "colab_type": "code",
        "outputId": "84288586-8503-43fc-bb1c-2d9d44738df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# Pandas dataframe\n",
        "data = pd.read_csv(file_path, sep=\"\\n\", header=None)\n",
        "\n",
        "pprint.pprint(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   0\n",
            "0                                                <p>\n",
            "1  Christmas won't be Christmas without any prese...\n",
            "2  It's so dreadful to be poor! sighed Meg, looki...\n",
            "3  I don't think it's fair for some girls to have...\n",
            "4  We've got Father and Mother, and each other, s...\n",
            "5  The four young faces on which the firelight sh...\n",
            "6                                               </p>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pAqn3VoFerW",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCG6Q1PBItFh",
        "colab_type": "text"
      },
      "source": [
        "## **Step 2. Clean Text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niLa0m2a0A5T",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLTY9PHhDx7X",
        "colab_type": "text"
      },
      "source": [
        "### **Study your data**\n",
        "\n",
        "Some questions to consider:\n",
        "\n",
        "- Is there any encoding error?\n",
        "\n",
        "- Should I remove tags?\n",
        "\n",
        "- Is there any unnecessary spaces?\n",
        "\n",
        "- Are the punctuations important?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMVFyE6VFcNK",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHe8_ZbOdUhm",
        "colab_type": "text"
      },
      "source": [
        "**What's in *example.txt*:**\n",
        "\n",
        "< p >\n",
        "\n",
        "\"Christmas won't be Christmas without any presents,\" grumbled Jo, lying on the rug.< br >\n",
        "\"It's so dreadful to be poor!\" sighed Meg, looking down at her old dress.< br >\n",
        "\"I don't think it's fair for some girls to have plenty of pretty things, and other girls nothing at all,\" added little Amy, with an injured sniff.< br >\n",
        "\"We've got Father and Mother, and each other,\" said Beth contentedly from her corner.< br >\n",
        "The four young faces on which the firelight shone brightened at the cheerful words, but darkened again as Jo said sadly, \"We haven't got Father, and shall not have him for a long time.\" She didn't say \"perhaps never,\" but each silently added it, thinking of Father far away, where the fighting was.< br >\n",
        "\n",
        "< /p >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geedaLy1FTQD",
        "colab_type": "text"
      },
      "source": [
        " >"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGG42rS9KTJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocessing(data):\n",
        "    new_data = []\n",
        "    new_sentence = \"\"\n",
        "    for sentence in (data[:][0]):\n",
        "        new_sentence = re.sub('<.*?>', '', sentence) # remove HTML tags\n",
        "        #new_sentence = re.sub(r'[^\\w\\s]', '', new_sentence) # remove punctuation\n",
        "        new_sentence = new_sentence.lower() # convert to lower case\n",
        "        if new_sentence != '':\n",
        "            new_data.append(new_sentence)\n",
        "    return new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP3PlVWOFf6i",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIhOARCRC-rw",
        "colab_type": "text"
      },
      "source": [
        "***Why would you consider converting text into lower cases?***\n",
        "\n",
        ">All these are considered different words:\n",
        "\n",
        ">CHRISTMAS, Christmas, christmas, ChRiStMaS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGUhEl6jHYnq",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgJw8_pgHazz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "***Some example of cases where you would keep the letter cases***\n",
        "\n",
        ">When your task requires an analysis on proper nouns such as names of location, organizations and/or human names.\n",
        "\n",
        ">>- \"Buttons\" as a cat name **vs** \"buttons\" as objects\n",
        "\n",
        ">>- \"Fluffy\" as a cat name **vs** ''fluffy\" as an adjective describing a property"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugpk6LR9FhNy",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNMV8LxTKiu1",
        "colab_type": "code",
        "outputId": "b1fe6846-95ed-4ccc-f9dc-63a73ae57315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "cleaned_data = preprocessing(data)\n",
        "pprint.pprint(cleaned_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"christmas won't be christmas without any presents, grumbled jo, lying on the \"\n",
            " 'rug.',\n",
            " \"it's so dreadful to be poor! sighed meg, looking down at her old dress.\",\n",
            " \"i don't think it's fair for some girls to have plenty of pretty things, and \"\n",
            " 'other girls nothing at all, added little amy, with an injured sniff.',\n",
            " \"we've got father and mother, and each other, said beth contentedly from her \"\n",
            " 'corner.',\n",
            " 'the four young faces on which the firelight shone brightened at the cheerful '\n",
            " 'words, but darkened again as jo said sadly, \"we haven\\'t got father, and '\n",
            " 'shall not have him for a long time.\" she didn\\'t say \"perhaps never,\" but '\n",
            " 'each silently added it, thinking of father far away, where the fighting was.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxYZwzWSFigF",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ACWAsiLRzM",
        "colab_type": "text"
      },
      "source": [
        "## **Step 3. Tokenize into words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m78ZvbKQ3hmG",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STDU9DjgLdu0",
        "colab_type": "code",
        "outputId": "32fc8f6a-f48c-4942-898c-587fa3503d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "\n",
        "token_text = [word_tokenize(d) for d in cleaned_data] # tokenizes without removing punctuation\n",
        "print(token_text[0])\n",
        "\n",
        "token_text = [tokenizer.tokenize(d) for d in cleaned_data] # tokenizes with punctuations removed\n",
        "print(token_text[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['christmas', 'wo', \"n't\", 'be', 'christmas', 'without', 'any', 'presents', ',', 'grumbled', 'jo', ',', 'lying', 'on', 'the', 'rug', '.']\n",
            "['christmas', 'won', 't', 'be', 'christmas', 'without', 'any', 'presents', 'grumbled', 'jo', 'lying', 'on', 'the', 'rug']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qbrp4VoUg1V",
        "colab_type": "text"
      },
      "source": [
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n9Qzf3wRBHc",
        "colab_type": "text"
      },
      "source": [
        "## **Step 4. More Processing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PQZtoXwJX2U",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn90_1eLI-Cj",
        "colab_type": "text"
      },
      "source": [
        "### **a. Remove stop words**\n",
        "*Removing commonly used word (such as “the”, “a”, “an”, “in”)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPlPHqsUJ5KS",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwedwnn9LFnE",
        "colab_type": "text"
      },
      "source": [
        "**Why would you REMOVE stop words?**\n",
        "> If you are using some bag of words based methods that works on counts and frequency of the words, removing stop words is great as it lowers the dimensional space and also a few stop words won't drive your analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu1BCh7MJ8HX",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NpBAHrzJzaI",
        "colab_type": "text"
      },
      "source": [
        "***Why would you KEEP stop words?***\n",
        "\n",
        ">In the context of sentiment analysis, removing stop words can be problematic if context is affected.\n",
        "\n",
        ">> example:\n",
        ">>> \"**I do not** like **this** movie\"  **vs** \"I like **this** movie\"\n",
        "\n",
        ">>> ---> *[I, do, not, this] are stop words*\n",
        "\n",
        ">>> **output**: \"like movie\" **vs** \"like movie\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "671tnwHAJud3",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zAYab3L2jS",
        "colab_type": "code",
        "outputId": "e1998107-7b4f-49da-a176-ba3c4dec84ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "print(stop_words[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv0GySJ5Kx_-",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4JAj7HhMnyy",
        "colab_type": "code",
        "outputId": "7a142ce1-9843-4d9d-bffb-ad623af73b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "rm_stop = [[word for word in sent if word not in stop_words] for sent in token_text]\n",
        "pprint.pprint(rm_stop[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['christmas',\n",
            " 'christmas',\n",
            " 'without',\n",
            " 'presents',\n",
            " 'grumbled',\n",
            " 'jo',\n",
            " 'lying',\n",
            " 'rug']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCydGvodJaIm",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HQIjNnoRKIT",
        "colab_type": "text"
      },
      "source": [
        "### **b. Lemmatization**\n",
        "*The process of grouping together the different inflected forms of a word so they can be analysed as a single item*\n",
        "\n",
        "\n",
        "> **Examples of lemmatization:**\n",
        "\n",
        ">rocks -> rock\n",
        "\n",
        ">corpora -> corpus\n",
        "\n",
        ">better -> good\n",
        "\n",
        ".\n",
        "\n",
        "***Why would you lemmatize the data?***\n",
        "> We want to make our system recognize different forms of words as same tokens.\n",
        "\n",
        ">> rocks, rock -> rock\n",
        "\n",
        ">> corpora, corpus -> corpus\n",
        "\n",
        ">> better, well, good -> good"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-6BnhRCRNzB",
        "colab_type": "code",
        "outputId": "34be47cd-a794-4790-cbed-2953a51eee54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) # a for adj"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rkstlNrRdv2",
        "colab_type": "code",
        "outputId": "23175ae4-138d-47f3-fa70-b7b3c7d239a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "lemm_data = [[lemmatizer.lemmatize(word) for word in sent] for sent in token_text]\n",
        "print(lemm_data)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['christmas', 'won', 't', 'be', 'christmas', 'without', 'any', 'present', 'grumbled', 'jo', 'lying', 'on', 'the', 'rug'], ['it', 's', 'so', 'dreadful', 'to', 'be', 'poor', 'sighed', 'meg', 'looking', 'down', 'at', 'her', 'old', 'dress'], ['i', 'don', 't', 'think', 'it', 's', 'fair', 'for', 'some', 'girl', 'to', 'have', 'plenty', 'of', 'pretty', 'thing', 'and', 'other', 'girl', 'nothing', 'at', 'all', 'added', 'little', 'amy', 'with', 'an', 'injured', 'sniff'], ['we', 've', 'got', 'father', 'and', 'mother', 'and', 'each', 'other', 'said', 'beth', 'contentedly', 'from', 'her', 'corner'], ['the', 'four', 'young', 'face', 'on', 'which', 'the', 'firelight', 'shone', 'brightened', 'at', 'the', 'cheerful', 'word', 'but', 'darkened', 'again', 'a', 'jo', 'said', 'sadly', 'we', 'haven', 't', 'got', 'father', 'and', 'shall', 'not', 'have', 'him', 'for', 'a', 'long', 'time', 'she', 'didn', 't', 'say', 'perhaps', 'never', 'but', 'each', 'silently', 'added', 'it', 'thinking', 'of', 'father', 'far', 'away', 'where', 'the', 'fighting', 'wa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtlu3z5pJbr2",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhSLREg1SM6R",
        "colab_type": "text"
      },
      "source": [
        "### **c. Stemming**\n",
        "*Producing morphological variants of a root/base word*\n",
        "\n",
        "\n",
        ">**Example of stemming:**\n",
        "\n",
        ">likes, liked, likely, liking -> like\n",
        "\n",
        ">chocolates,chocolatey -> choco\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdaibjFBR5V7",
        "colab_type": "code",
        "outputId": "e9191f44-d661-4033-f9da-411d64f9d678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "   \n",
        "ps = PorterStemmer() \n",
        "  \n",
        "words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
        "  \n",
        "for w in words: \n",
        "    print(w, \" : \", ps.stem(w)) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programer  :  program\n",
            "programing  :  program\n",
            "programers  :  program\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYGrKEx3SHAl",
        "colab_type": "code",
        "outputId": "9ea47b25-b5ad-40dc-c7f2-8f0848f0d9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "stem_data = [[ps.stem(word) for word in sent] for sent in token_text]\n",
        "print(stem_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['christma', 'won', 't', 'be', 'christma', 'without', 'ani', 'present', 'grumbl', 'jo', 'lie', 'on', 'the', 'rug'], ['it', 's', 'so', 'dread', 'to', 'be', 'poor', 'sigh', 'meg', 'look', 'down', 'at', 'her', 'old', 'dress'], ['i', 'don', 't', 'think', 'it', 's', 'fair', 'for', 'some', 'girl', 'to', 'have', 'plenti', 'of', 'pretti', 'thing', 'and', 'other', 'girl', 'noth', 'at', 'all', 'ad', 'littl', 'ami', 'with', 'an', 'injur', 'sniff'], ['we', 've', 'got', 'father', 'and', 'mother', 'and', 'each', 'other', 'said', 'beth', 'contentedli', 'from', 'her', 'corner'], ['the', 'four', 'young', 'face', 'on', 'which', 'the', 'firelight', 'shone', 'brighten', 'at', 'the', 'cheer', 'word', 'but', 'darken', 'again', 'as', 'jo', 'said', 'sadli', 'we', 'haven', 't', 'got', 'father', 'and', 'shall', 'not', 'have', 'him', 'for', 'a', 'long', 'time', 'she', 'didn', 't', 'say', 'perhap', 'never', 'but', 'each', 'silent', 'ad', 'it', 'think', 'of', 'father', 'far', 'away', 'where', 'the', 'fight', 'wa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WADkctyFNpAy",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a54yaN7KJc9b",
        "colab_type": "text"
      },
      "source": [
        "***Lemmatization vs Stemming***\n",
        "\n",
        "Lemmatization performs morphological analysis so it preserves the context of words\n",
        "\n",
        "wheras stemming cuts off parts of words so the morphological variants produced are not always real words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DadNUW8fNqWZ",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFW745etU7Xo",
        "colab_type": "text"
      },
      "source": [
        "## **Step 6. Text featurization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCwHkCjIV6zo",
        "colab_type": "text"
      },
      "source": [
        "### **Bag of words**\n",
        "\n",
        "Text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity.\n",
        "\n",
        ".\n",
        "\n",
        "**Step 1.** Create vocabulary\n",
        "\n",
        "![alt text](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/assets/atap_0401.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Step 2.** Encode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ_MZRnvuwTl",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlGrX7abdQD9",
        "colab_type": "text"
      },
      "source": [
        "### **a. Count/frequency based BOW**\n",
        "\n",
        "*Counts how many times each word appears in a sentence from the bag*\n",
        "\n",
        "![alt text](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/assets/atap_0402.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y0eeTcxeQTA",
        "colab_type": "code",
        "outputId": "4b1c4ecf-be88-41aa-eec5-239d993b599f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectors = vectorizer.fit_transform(data[:][0])\n",
        "\n",
        "print(vectors[1].toarray())\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcM-7qzSuyLb",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aBYuV9sdw8W",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### **b. Binary one-hot encoding**\n",
        "\n",
        "*Checks the existance of words in a sentence from the bag*\n",
        "\n",
        "![alt text](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/assets/atap_0403.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYbuCcMVea94",
        "colab_type": "code",
        "outputId": "ec9e2d81-10b8-45e9-f89b-3124c9f40354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "freq   = CountVectorizer()\n",
        "corpus = freq.fit_transform(data[:][0])\n",
        "\n",
        "onehot = Binarizer()\n",
        "corpus = onehot.fit_transform(corpus)\n",
        "\n",
        "print(corpus[1].toarray())\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOf3uO8YuztP",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM1J4LRFdyrk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### **c. TF-IDF**\n",
        "\n",
        "*TF-IDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.*\n",
        "\n",
        "*The value increases proportionally to the number of times a word appears in the sentence and is offset by the number of sentences in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.*\n",
        "\n",
        "![alt text](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/assets/atap_0404.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDDoiwFLejgA",
        "colab_type": "code",
        "outputId": "9102c4e4-4467-4f66-9f44-c901aace16cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf  = TfidfVectorizer()\n",
        "corpus = tfidf.fit_transform(data[:][0])\n",
        "\n",
        "print(corpus[1].toarray())\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.26681038 0.         0.         0.         0.22147553 0.\n",
            "  0.14397509 0.         0.         0.         0.53362075 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.26681038 0.         0.         0.         0.\n",
            "  0.         0.         0.22147553 0.         0.         0.\n",
            "  0.26681038 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.22147553 0.         0.         0.\n",
            "  0.         0.26681038 0.         0.26681038 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.22147553 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.26681038 0.26681038 0.\n",
            "  0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yizLfhIexhuY",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn3LlwdYxi6e",
        "colab_type": "text"
      },
      "source": [
        "***Pros and Cons of Bag-of-words representations:***\n",
        "\n",
        "> **Pros:** Can work with small amount of data. Different preprocessing methods can help control the dimentionality.\n",
        "\n",
        "> **Cons:** Does not take context of text into account. Syntactic and semantic information is lost.\n",
        ">> ie. These sentences will be considerd the same:\n",
        " >>>The king threw a ball at a dog.\n",
        " \n",
        " >>>A dog threw a ball at the king."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0qJWCkj2Gjz",
        "colab_type": "text"
      },
      "source": [
        "### N-gram\n",
        "\n",
        "*An n-gram is a n-tuple or group of n words or characters (grams, for pieces of grammar) which follow one another. So an n of 3 for the words from your sentence would be like \"# I live\", \"I live in\", \"live in NY\", \"in NY #\". This is used to create an index of how often words follow one another.*\n",
        "\n",
        "\n",
        "![alt text](https://i.stack.imgur.com/8ARA1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3IpP49Cu1Li",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lldVWoMeEMqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4163
        },
        "outputId": "17816f88-e895-4774-d857-d78db0b3bf0f"
      },
      "source": [
        "\n",
        "bigram = CountVectorizer(ngram_range=(2,2)) # bigram example(unigram range(1,1),bigram(2,2),trigram(3,3),...)\n",
        "\n",
        "corpus = bigram.fit_transform(data[:][0])\n",
        "\n",
        "print(corpus[1].toarray())\n",
        "[print(w) for w in bigram.get_feature_names()]\n",
        "    \n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 1 1 0 0]]\n",
            "added it\n",
            "added little\n",
            "again as\n",
            "all added\n",
            "amy with\n",
            "an injured\n",
            "and each\n",
            "and mother\n",
            "and other\n",
            "and shall\n",
            "any presents\n",
            "as jo\n",
            "at all\n",
            "at her\n",
            "at the\n",
            "away where\n",
            "be christmas\n",
            "be poor\n",
            "beth contentedly\n",
            "brightened at\n",
            "but darkened\n",
            "but each\n",
            "cheerful words\n",
            "christmas without\n",
            "christmas won\n",
            "contentedly from\n",
            "corner br\n",
            "darkened again\n",
            "didn say\n",
            "don think\n",
            "down at\n",
            "dreadful to\n",
            "dress br\n",
            "each other\n",
            "each silently\n",
            "faces on\n",
            "fair for\n",
            "far away\n",
            "father and\n",
            "father far\n",
            "fighting was\n",
            "firelight shone\n",
            "for long\n",
            "for some\n",
            "four young\n",
            "from her\n",
            "girls nothing\n",
            "girls to\n",
            "got father\n",
            "grumbled jo\n",
            "have him\n",
            "have plenty\n",
            "haven got\n",
            "her corner\n",
            "her old\n",
            "him for\n",
            "injured sniff\n",
            "it fair\n",
            "it so\n",
            "it thinking\n",
            "jo lying\n",
            "jo said\n",
            "little amy\n",
            "long time\n",
            "looking down\n",
            "lying on\n",
            "meg looking\n",
            "mother and\n",
            "never but\n",
            "not have\n",
            "nothing at\n",
            "of father\n",
            "of pretty\n",
            "old dress\n",
            "on the\n",
            "on which\n",
            "other girls\n",
            "other said\n",
            "perhaps never\n",
            "plenty of\n",
            "poor sighed\n",
            "presents grumbled\n",
            "pretty things\n",
            "rug br\n",
            "sadly we\n",
            "said beth\n",
            "said sadly\n",
            "say perhaps\n",
            "shall not\n",
            "she didn\n",
            "shone brightened\n",
            "sighed meg\n",
            "silently added\n",
            "sniff br\n",
            "so dreadful\n",
            "some girls\n",
            "the cheerful\n",
            "the fighting\n",
            "the firelight\n",
            "the four\n",
            "the rug\n",
            "things and\n",
            "think it\n",
            "thinking of\n",
            "time she\n",
            "to be\n",
            "to have\n",
            "ve got\n",
            "was br\n",
            "we haven\n",
            "we ve\n",
            "where the\n",
            "which the\n",
            "with an\n",
            "without any\n",
            "won be\n",
            "words but\n",
            "young faces\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeLF3QAaISZM",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwH63xbiISzO",
        "colab_type": "text"
      },
      "source": [
        "**Pros and Cons**\n",
        "\n",
        "The N-gram model, like many statistical models, is very dependent on the training corpus. One implication of this is that the probabilities often encode very specific facts about a given training corpus. Another implication is that N-grams do a better and better job of modeling the training corpus as we increase the value of N."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwn-R-pEIbLz",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tchd8aPTYp8D",
        "colab_type": "text"
      },
      "source": [
        "### **Word Embedding**\n",
        "\n",
        "*Vector representations of words*\n",
        "\n",
        "![alt text](https://shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com/wp-content/uploads/2018/01/word-vector-space-similar-words.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7VYucgPw2bf",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7adoH9Rw3er",
        "colab_type": "text"
      },
      "source": [
        "***Pros and Cons of Word Embeddings:***\n",
        "\n",
        "> **Pros:**\n",
        ">- Capable of capturing context of a word in a document,\n",
        ">- Semantic and syntactic similarity, relation with other words.\n",
        "\n",
        "> **Cons:** \n",
        "\n",
        ">- Large amount of data required for training.\n",
        "> -Word embeddings are known for containing biases and debiasing trained embeddings does not remove biases entirely.\n",
        ">- Words with the same spellings with different meanings will be considered the same.\n",
        "\n",
        ">>> Walls that cannot **bear** a stone vault\n",
        "\n",
        ">>> How to be a good mama ***bear***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA37Po9Ww44V",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fye-MrcnfPwz",
        "colab_type": "code",
        "outputId": "23f08a23-7a9f-49af-933c-0ade502021cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Word2vec model for embeddings  \n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(size=300)\n",
        "model.build_vocab(token_text)\n",
        "\n",
        "total_examples = model.corpus_count # len corpus\n",
        "model.train(token_text, total_examples=total_examples, epochs=model.epochs)\n",
        "\n",
        "\n",
        "X_data = model[model.wv.vocab]\n",
        "words = list(model.wv.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6-taRvEhnsK",
        "colab_type": "code",
        "outputId": "c3a03d68-b2cc-46b0-e92b-067e4e7cf1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1330
        }
      },
      "source": [
        "model.wv['christmas']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.54286833e-03, -1.65511540e-03, -3.94200397e-05,  8.41436733e-04,\n",
              "        1.22157449e-03,  3.10122879e-04,  4.81995703e-05, -4.56807757e-04,\n",
              "       -7.90196413e-04, -4.09548433e-04,  1.28969131e-03,  2.05074291e-04,\n",
              "        1.05342537e-03,  5.16896893e-04,  6.29765331e-04, -1.46103022e-03,\n",
              "       -1.09345556e-05,  8.13270570e-04,  6.35003846e-04,  4.06869513e-04,\n",
              "        3.47754365e-04,  6.57792727e-04,  1.29037525e-03,  1.49559265e-03,\n",
              "        1.14368740e-03, -3.85907595e-04,  2.14804852e-04, -3.97174241e-04,\n",
              "        1.06305641e-03, -1.24074775e-03,  6.78825541e-04,  6.65061671e-05,\n",
              "       -1.47427330e-04,  1.61041308e-03,  6.63857674e-04,  1.72056083e-04,\n",
              "       -4.65855497e-04,  5.62146830e-04, -1.08092767e-03, -1.28072267e-03,\n",
              "        6.68620167e-04,  5.32450969e-04, -1.07941160e-03, -1.28256751e-03,\n",
              "       -7.81939540e-04,  9.98259289e-04,  7.94147898e-04,  2.18402070e-04,\n",
              "       -2.93476012e-04,  1.11167668e-03, -6.87367690e-04,  2.64775910e-04,\n",
              "       -5.75456186e-04,  1.10356428e-04, -4.22994199e-04, -1.47428433e-03,\n",
              "        1.51401517e-04,  1.27191446e-03, -6.95568742e-04, -7.11247674e-04,\n",
              "        1.45399582e-03,  1.21373247e-04, -5.97122125e-04, -8.37703119e-04,\n",
              "       -1.29984936e-03, -1.25041639e-03, -1.25718222e-03, -3.94093775e-04,\n",
              "        1.17475470e-03, -1.30186579e-03, -9.79716075e-04, -3.10755451e-04,\n",
              "       -5.40269015e-04, -6.43155886e-07, -1.65906164e-03, -5.13760606e-04,\n",
              "       -1.40393164e-03, -7.25273276e-04, -9.70445763e-05, -3.35709337e-05,\n",
              "        4.54898895e-04, -1.30000466e-03, -1.65164471e-03,  9.95949144e-04,\n",
              "       -1.02708489e-03, -1.25614123e-03,  9.41083592e-04,  8.00088688e-04,\n",
              "       -1.59649295e-03,  1.54234597e-03,  7.41859549e-04,  7.56098249e-04,\n",
              "        4.46696969e-04,  4.44931793e-04,  1.58583035e-03, -9.49119218e-04,\n",
              "       -9.38202604e-04, -1.15241739e-03, -4.35747716e-05, -1.52036897e-03,\n",
              "        5.80126129e-04,  1.04296848e-03,  1.52770558e-03,  5.74817997e-04,\n",
              "        5.92661789e-04,  8.80547450e-04, -1.18496153e-03, -3.65779328e-04,\n",
              "        1.31824485e-03, -1.09780964e-03, -1.27191283e-03, -2.79696396e-05,\n",
              "        3.58540477e-04, -4.87173209e-04, -8.29724246e-04, -9.73151939e-04,\n",
              "        1.49588229e-03,  1.46657228e-03,  5.03542367e-04,  1.12601893e-03,\n",
              "        5.55275219e-05, -1.20388533e-04, -6.36555429e-04,  1.45530037e-03,\n",
              "       -1.32221461e-03, -1.88939273e-04,  1.25557731e-03,  8.40814144e-04,\n",
              "       -1.29021960e-03, -1.46899431e-03, -3.07412352e-04,  9.14883043e-04,\n",
              "       -1.06067967e-03,  5.94641780e-04, -1.10257114e-03,  9.06104280e-04,\n",
              "        1.34686253e-03,  1.29279355e-03, -1.09904923e-03,  5.44862123e-04,\n",
              "        6.23399275e-04, -1.48602191e-03, -6.50950009e-04,  1.20314385e-03,\n",
              "        5.61409688e-04,  1.08406704e-03, -1.61454477e-03,  3.71170579e-04,\n",
              "        8.62369954e-04,  9.52539907e-04,  5.24854113e-04, -2.76168401e-04,\n",
              "       -8.46394512e-04, -4.56523761e-04, -2.84054295e-05, -2.57976411e-04,\n",
              "       -1.54956069e-03,  7.73405132e-04, -4.14136994e-05,  5.87169954e-04,\n",
              "        2.74072925e-04, -1.19702530e-03,  1.26579066e-03, -1.63990259e-03,\n",
              "        1.01782556e-03,  2.14043263e-04,  2.41782836e-04, -3.80968733e-04,\n",
              "        9.97175230e-04,  1.51138962e-03,  1.59495499e-03,  1.82180564e-04,\n",
              "        1.03637576e-03,  5.95639794e-05, -1.54765043e-03, -1.54996742e-04,\n",
              "       -1.28612434e-03, -1.24647655e-03, -8.27406984e-05,  1.15848015e-04,\n",
              "       -2.46371899e-04, -7.38384610e-04, -1.48473238e-03, -1.59946189e-03,\n",
              "        5.45415678e-04,  1.21583196e-03, -1.25534856e-03, -1.35951885e-03,\n",
              "       -4.34138026e-04, -7.25433871e-04, -2.38763696e-05,  8.09321296e-04,\n",
              "       -1.55564630e-03,  9.71634872e-04, -7.51153100e-04,  9.17881320e-04,\n",
              "       -2.16514512e-04, -7.69199047e-04, -4.53018001e-04, -1.05411897e-03,\n",
              "        1.47110061e-03, -4.98121895e-04,  5.87903836e-04,  6.15613535e-04,\n",
              "       -1.57774368e-04,  1.45319360e-03, -1.06698729e-03, -9.39671707e-04,\n",
              "       -6.35121134e-04,  8.87856178e-04,  9.50472779e-04, -4.64667646e-05,\n",
              "       -1.39320467e-03, -6.50613802e-04,  7.28619110e-04,  3.09492054e-04,\n",
              "        1.55514485e-04,  1.60284876e-03,  1.20286341e-03,  1.06412184e-03,\n",
              "        3.68436740e-04, -9.78140160e-04, -6.34157856e-04, -1.43443816e-03,\n",
              "        1.55520241e-03,  1.02491176e-03,  5.49700286e-04,  7.13085174e-04,\n",
              "        1.28393818e-03, -1.66401116e-03, -8.44609633e-04,  5.06220444e-04,\n",
              "        1.27079885e-03,  1.40548544e-03,  5.56528568e-04, -1.51603762e-03,\n",
              "       -1.65977236e-03,  1.15768914e-03,  1.41139585e-03, -3.58956808e-04,\n",
              "        3.78011580e-04, -8.89330811e-04, -1.19882333e-03, -5.53619349e-04,\n",
              "        1.62902870e-03,  3.55425407e-04,  1.34257134e-03,  1.05671980e-03,\n",
              "       -4.33614710e-04,  7.15713832e-04,  1.05155064e-04, -1.51692447e-03,\n",
              "        1.50894513e-03,  2.24644493e-04, -7.04932609e-04, -1.55196688e-03,\n",
              "        1.06507575e-03,  4.96776076e-04,  9.41840291e-04, -4.95865941e-04,\n",
              "        1.57932728e-03, -8.64624337e-04, -1.11845475e-04, -2.48460536e-04,\n",
              "       -1.56352262e-03, -1.05858094e-03, -1.32148212e-03,  1.07722019e-03,\n",
              "        6.73412462e-04,  6.32908719e-04,  3.58620513e-04, -1.40344980e-03,\n",
              "        1.41597015e-03, -1.38804398e-03,  3.79071629e-04,  1.16366032e-03,\n",
              "        3.93434690e-04,  1.28967385e-03, -4.01122583e-04,  1.60551840e-03,\n",
              "        1.77341804e-04, -1.10248337e-03,  1.04779878e-03,  8.86977650e-04,\n",
              "       -1.08779978e-03, -1.82056916e-04,  3.72225535e-04,  1.06082472e-03,\n",
              "       -5.67253504e-04,  1.22532959e-03,  5.64562215e-04, -2.82281544e-04,\n",
              "        5.23949333e-04, -8.84963840e-04, -8.59545311e-04,  1.51023269e-03,\n",
              "        1.20575505e-03, -1.36501412e-03,  8.43532616e-04,  8.67161143e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uA8kbnfiW0q",
        "colab_type": "code",
        "outputId": "7ac008bd-713a-49b7-d516-37b1830bf567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.wv.most_similar('christmas')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('faces', 0.14987346529960632),\n",
              " ('things', 0.1376577764749527),\n",
              " ('t', 0.10588370263576508),\n",
              " ('but', 0.0995744988322258),\n",
              " ('silently', 0.07620739191770554),\n",
              " ('without', 0.07240990549325943),\n",
              " ('and', 0.0710473582148552),\n",
              " ('some', 0.06711910665035248),\n",
              " ('any', 0.06545284390449524),\n",
              " ('thinking', 0.06207112967967987)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sts7KE2E0a6y",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8wxBSAh0cRA",
        "colab_type": "text"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1682zfNAY8AN",
        "colab_type": "text"
      },
      "source": [
        "## **TorchText**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRCivqI10sPL",
        "colab_type": "text"
      },
      "source": [
        "PyTorch package for text preprocessing: [TorchText document](https://torchtext.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGklajU1lBuF",
        "colab_type": "code",
        "outputId": "5f2cfcfa-c727-4e89-ca9b-3c8a11f702aa",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# google file open\n",
        "file_path_csv = \"./example.csv\"\n",
        "if not os.path.isfile(file_path_csv):\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "# Pandas dataframe\n",
        "csv_data = pd.read_csv(file_path_csv,error_bad_lines=False)\n",
        "pprint.pprint(csv_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ac9a4556-690a-491a-bec0-60b326516864\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ac9a4556-690a-491a-bec0-60b326516864\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving example.csv to example.csv\n",
            "   ID                                           Sentence  Label\n",
            "0   1  Christmas won't be Christmas without any prese...      0\n",
            "1   2  It's so dreadful to be poor! sighed Meg, looki...      1\n",
            "2   3  I don't think it's fair for some girls to have...      0\n",
            "3   4  We've got Father and Mother, and each other, s...      1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX72cMA-ZAfw",
        "colab_type": "code",
        "outputId": "00b12617-d63d-4e54-f1ee-7f8c3efe7d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torchtext.data import Field\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.vocab import GloVe, Vectors\n",
        "\n",
        "# You can define your own tokenizer or call onto existing\n",
        "tokenize = lambda x: lemmatizer.lemmatize(re.sub(r'<.*?>|[^\\w\\s]|\\d+', '', x)).split()  tokenizers\n",
        "\n",
        "# Define your field placeholders\n",
        "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)\n",
        "LABEL = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "\n",
        "csv_data = TabularDataset(file_path_csv, format=\"csv\",\n",
        "                          fields = [(\"ID\", None),(\"Sentence\", TEXT), (\"Label\", LABEL)])\n",
        "\n",
        "# Build your vocabulary bank\n",
        "TEXT.build_vocab(csv_data, max_size=200, vectors=GloVe(name='6B', dim=300))\n",
        "word_emb = TEXT.vocab.vectors\n",
        "\n",
        "LABEL.build_vocab(csv_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [00:50, 17.2MB/s]                           \n",
            "100%|█████████▉| 399957/400000 [00:46<00:00, 8686.71it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F1Dc1lXnADE",
        "colab_type": "code",
        "outputId": "c6a6db7a-729e-49e6-b1be-43fb0991675d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Word List\n",
        "word_lst =list(TEXT.vocab.itos)\n",
        "print(word_lst)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'and', 'at', 'be', 'christmas', 'girls', 'her', 'its', 'other', 'to', 'added', 'all', 'amy', 'an', 'any', 'beth', 'contentedly', 'corner', 'dont', 'down', 'dreadful', 'dress', 'each', 'fair', 'father', 'for', 'from', 'got', 'grumbled', 'have', 'i', 'injured', 'jo', 'little', 'looking', 'lying', 'meg', 'mother', 'nothing', 'of', 'old', 'on', 'plenty', 'poor', 'presents', 'pretty', 'rug', 'said', 'sentence', 'sighed', 'sniff', 'so', 'some', 'the', 'things', 'think', 'weve', 'with', 'without', 'wont']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umXTpZBPqGCT",
        "colab_type": "code",
        "outputId": "2c525ca0-d310-45d8-d5b0-59c4b7840d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "source": [
        "print(word_lst[20])\n",
        "print(word_emb[20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "down\n",
            "tensor([-8.1429e-02, -1.1004e-01, -3.1034e-02,  6.0457e-01,  6.7606e-02,\n",
            "        -3.1609e-01, -4.6059e-01, -2.0273e-01,  4.6852e-01, -1.6009e+00,\n",
            "        -4.5330e-01, -1.9684e-01,  2.0119e-01, -1.7361e-01, -1.0069e-01,\n",
            "         3.7192e-01, -4.9373e-02,  2.2970e-01, -2.1218e-01, -4.1316e-02,\n",
            "        -2.7262e-01,  3.8110e-01,  4.9122e-01, -2.0979e-01, -5.1443e-01,\n",
            "        -3.5561e-01,  2.2332e-01, -2.4093e-01, -3.2059e-03,  4.0946e-02,\n",
            "         2.2596e-03,  2.5204e-01, -1.7363e-02,  1.3675e-01, -1.3253e+00,\n",
            "        -1.4328e-01, -4.2798e-02,  1.5638e-01, -3.2210e-01, -1.0234e-01,\n",
            "        -2.9886e-01,  1.5377e-01, -3.6970e-01,  2.0354e-01, -2.2908e-01,\n",
            "         4.0350e-01,  3.7391e-01,  4.7247e-01,  4.1236e-02, -2.6902e-01,\n",
            "        -2.5978e-01, -1.1549e-01, -5.9670e-02, -3.8557e-01, -1.7710e-01,\n",
            "         5.7339e-02, -1.3457e-02,  1.4074e-01,  5.2561e-02, -8.4316e-02,\n",
            "         1.8599e-01,  5.2734e-02,  2.2400e-01, -1.5718e-02, -1.9844e-01,\n",
            "        -7.7889e-01,  8.4829e-02,  2.6423e-01,  1.1346e-01, -2.5382e-01,\n",
            "         1.9409e-01,  2.8628e-01, -4.2394e-01,  2.0190e-01,  6.1871e-01,\n",
            "        -2.5224e-01, -1.4918e-01,  1.7495e-01, -1.6068e-01, -1.3570e-02,\n",
            "        -3.1032e-01, -5.5676e-01,  3.6292e-01,  2.3678e-01, -3.9157e-03,\n",
            "         8.0145e-02, -1.5942e-01,  4.3440e-01, -1.4311e-01,  4.8187e-02,\n",
            "         1.8608e-01, -9.2186e-02, -2.1727e-01, -1.6223e-01, -1.0287e-03,\n",
            "        -2.9389e-01, -8.0861e-01,  4.5484e-02,  1.9271e-01, -3.6306e-01,\n",
            "         6.2891e-02,  5.3628e-02,  2.2844e-01,  2.6019e-01, -8.7470e-02,\n",
            "        -5.5060e-01,  3.9837e-01,  3.1690e-01, -2.9759e-01,  3.8910e-01,\n",
            "        -6.2897e-01, -7.2113e-01, -9.0281e-02, -4.3020e-01, -1.0947e-01,\n",
            "         4.9687e-01,  1.3661e-01, -1.1130e-03, -3.1758e-01, -6.1091e-01,\n",
            "        -2.2543e-01, -5.7949e-01,  8.5977e-02,  1.5255e-01, -2.3990e-01,\n",
            "        -1.4142e-01,  2.0866e-01, -3.9507e-03, -2.2283e-01, -1.3949e-01,\n",
            "        -3.8991e-01,  6.9410e-01,  1.2609e-01,  2.4304e-01,  2.6163e-01,\n",
            "         3.1018e-01,  2.8239e-01,  9.1971e-02, -1.3998e-01,  1.9491e-01,\n",
            "         4.3517e-01, -1.6054e-01, -1.1753e-01,  7.8824e-01, -1.3378e+00,\n",
            "         4.4547e-01, -3.1675e-01, -2.1942e-01, -1.1469e-01, -2.1100e-01,\n",
            "         2.3052e-01,  3.1071e-01, -2.2245e-01, -5.8431e-02,  8.5367e-01,\n",
            "         1.9937e-01, -1.1716e-01, -1.8605e-01,  2.6697e-01,  3.1276e-02,\n",
            "        -1.1202e-01, -1.7063e-01, -1.1566e-01, -2.2268e-01,  2.0799e-01,\n",
            "         3.2008e-02,  2.7819e-01,  2.7076e-01,  8.6183e-03,  1.6088e-01,\n",
            "        -1.6457e-01,  2.2996e-01,  4.4692e-02, -2.9411e-01,  2.7579e-01,\n",
            "        -1.2753e-01,  1.7538e-01,  4.0261e-01,  8.2017e-02,  4.7507e-01,\n",
            "        -5.9245e-02,  1.7938e-01,  2.6704e-01,  1.8184e-01, -3.3024e-01,\n",
            "        -3.6489e-01, -9.3083e-03,  6.1190e-02,  1.9804e-01, -1.2530e-01,\n",
            "         2.5385e-02,  9.5832e-02, -3.3058e-01, -3.1737e-02, -1.2239e-01,\n",
            "        -3.1603e-01, -6.2607e-01, -3.3293e-01,  4.4448e-01, -4.5576e-01,\n",
            "         1.2087e+00,  2.9586e-02,  1.0941e-01,  1.8790e-01, -2.0781e-01,\n",
            "         3.9291e-01,  1.0867e-01, -4.7106e-01,  2.5568e-02, -2.9462e-02,\n",
            "        -3.4244e-01, -3.9391e-01, -2.7913e-01,  5.0073e-02,  3.6237e-02,\n",
            "         3.1311e-01,  8.8226e-02,  1.2120e-01, -2.0487e-01,  1.4069e-01,\n",
            "         6.2009e-01, -3.4575e-02, -3.0751e-01, -2.3115e-01, -6.5017e-01,\n",
            "        -9.6079e-02,  3.2323e-01,  1.3176e-01, -2.1783e-01,  7.5021e-02,\n",
            "         1.2513e-01, -1.7993e-01, -4.8059e-01, -2.2553e-02,  3.7906e-01,\n",
            "         1.6495e-01,  2.8426e-01, -2.0347e-01,  1.0655e-01,  2.3264e-01,\n",
            "         2.0218e-01,  7.9759e-02,  3.3684e-02, -1.1993e-01, -4.6239e-01,\n",
            "        -4.3971e-01,  3.3866e-01, -3.2447e-02, -3.7182e-01,  3.0105e-01,\n",
            "         1.9778e-01, -2.4392e-01,  3.2866e-01, -4.4968e-01,  7.3862e-01,\n",
            "        -5.2219e-01, -4.4221e-01, -1.4291e-01, -4.6289e-01, -4.2005e-02,\n",
            "        -4.6134e-02, -3.6122e-01, -7.6364e-02,  1.3321e-01, -1.3733e-01,\n",
            "        -1.4888e-01,  4.4214e-02,  2.1131e-01, -3.9261e-01,  6.2531e-02,\n",
            "         1.2390e-01, -1.2035e-01,  1.9577e-01,  3.5788e-01, -5.6875e-01,\n",
            "        -1.0889e-01, -1.5971e+00, -2.6548e-01, -8.2227e-02,  1.3617e-01,\n",
            "        -3.1370e-01,  1.2832e-01,  2.3315e-01, -4.7355e-01,  9.6017e-02,\n",
            "         2.9856e-01, -2.3967e-01, -2.7037e-01, -8.5428e-02, -4.4404e-01,\n",
            "         2.1293e-01, -1.7290e-01,  1.3380e-02,  4.5064e-01,  1.2472e-01,\n",
            "         5.4997e-01, -1.9647e-01, -3.9002e-01, -6.2974e-02,  9.6852e-02])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njbVnCRy2NRA",
        "colab_type": "code",
        "outputId": "5a50a9ce-3264-4c9f-b4a8-9fc8af2ae112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# LABELS\n",
        "LABEL.vocab.itos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '0', '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZkihCd2yLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}